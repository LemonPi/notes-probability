-----------------------------------------------------------
    Conditional probability
-----------------------------------------------------------
- P(X|Y) probability of X given Y
- P(X|Y) = P(X and Y) / P(Y)
	- consider just the world of where Y is a certain value
	- see how X and Y coexist
- #P(X|Y) = P(Y|X) * P(X) / P(Y)#
	- useful for calculating effect of evidence
	- proof
		- P(X and Y) = P(X|Y)*P(Y) = P(Y|X)*P(X)

-----------------------------------------------------------
    Bayes Rule
-----------------------------------------------------------
- #prior odds * relative likelihood = posterior odds#
	- odds is a ratio of probability rather than the probabilities themselves
- fundamentally about how evidence updates our beliefs
	- evidence has strength signified by relative likelihood
- P(X|Y) we want to know; Y is the evidence
- prior odds is P(X) / P(-X)
- relative likelihood is P(Y|X) / P(Y|-X)
	- how likely is it to observe Y "correctly"
- posterior odds is P(X|Y) / P(-X|Y)
- P(X)/P(-X) * P(Y|X)/P(Y|-X) = P(X|Y)/P(-X|Y)
	- prove trivialy using the definition of conditional probability
	- P(Y|X) * P(X) = P(X and Y) by definition
	->P(X)/P(-X) * P(Y|X)/P(Y|-X)
	= P(X and Y) / P(-X and Y) 
	= P(X|Y)*P(Y) / P(-X|Y)*P(Y) using the same expansion
	= P(X|Y) / P(-X|Y) assuming P(Y) != 0

-----------------------------------------------------------
    Bayes thinking
-----------------------------------------------------------
- extraordinary claims require extraordinary evidence
	- relative likelihood has to be more extreme than prior odds
- evidence is never rejected
	- even if evidence is weak, it still provides information
	- even if evidence is strong, it may not be strong enough to overthrow a stronger prior
		- but still works to weaken the prior since in the future the posterior becomes the prior

-----------------------------------------------------------
    Log-odds perspective
-----------------------------------------------------------
- consider log(P)
	- information gain is additive
	- amount added is independent of prior
		- intuitively makes sense because evidence is independent of belief
- 0 bits of information is 50% chance
	- +1 bit means twice as likely, so n bits means the odds are 2^n : 1 of happening
		- 2^n / (2^n + 1) probability
- exposes illogical infinite credences
	- assigning hypothesis P(X) = 1 or 0 means inf or -inf on the log scale
	- no evidence can overturn prior

-----------------------------------------------------------
    Vector form
-----------------------------------------------------------
- multiple competing hypothesis H1, H2, ...
- ex
	- flip 3 coins and get THT
		- 1/2 of coins are fair and produce H with .5
		- 1/3 of coins produce H with .75
		- 1/6 of coins produce H with .25
		- calculate each hypothesis (that the coin flipped was from a certain population) together
		- [1/2 1/3 1/6] * [.5 .25 .75] * [.5 .75 .25] * [.5 .25 .75]
			- element-wise multiplication
			= [.0625 .015625 .0234375]
			->.0625/sum = 8/13 chance of the coin being fair
